[Camera]
# Use 0 for the default webcam or provide a URL for an external camera feed.
DROIDCAM_URL = 0

[Thresholds]
# Eye Aspect Ratio (EAR) threshold for blink detection.
EAR_THRESHOLD = 0.190
# Mouth Aspect Ratio (MAR) threshold for mouth open detection.
MAR_THRESHOLD = 0.083
# (Optional) Eyebrow Raise or similar thresholds.
EBR_THRESHOLD = 1.5
# Emotion detection threshold (if applicable).
EMOTION_THRESHOLD = 0.4

[WebSocket]
# Toggle WebSocket transmission.
ENABLE_WEBSOCKET = False
# WebSocket server URL (e.g., for VTube Studio or Unity integration).
VTS_WS_URL = ws://localhost:8001
# Authorization token if needed.
AUTH_TOKEN = your_auth_token

[Logging]
# Logging level: DEBUG, INFO, WARNING, ERROR, or CRITICAL.
LOG_LEVEL = INFO

[Animation]
# Smoothing factor controls the interpolation of animation data.
SMOOTHING_FACTOR = 0.8
# Interpolation type: linear, cubic, etc.
INTERPOLATION_TYPE = linear

[Calibration]
# Optional camera calibration parameters.
CAMERA_MATRIX =
CAMERA_DIST =

[Advanced]
# Toggle the advanced deep-learning based lip sync module.
USE_DEEP_LIP_SYNC = True
# Audio capture settings.
AUDIO_SAMPLE_RATE = 16000
AUDIO_DEVICE_ID = 0
# How frequently (in frames) to run the heavy lip sync inference.
LIP_SYNC_SKIP_FRAMES = 3
# Number of frames between running emotion analysis.
EMOTION_ANALYSIS_INTERVAL = 15
# Enable or disable debugging mode.
DEBUG_MODE = False
# Enable run-time emotion analysis if applicable.
RUN_EMOTION_ANALYSIS = True
# Path to the advanced lip sync model file.  
# (Make sure to download this model from: 
# https://drive.google.com/drive/folders/153HLrqlBNxzZcHi17PEvP09kkAfzRshM)
MODEL_PATH = models/Wav2Lip-SD-NOGAN.pt

[Emotion]
# Toggle emotion recognition. Requires DeepFace (optional).
USE_EMOTION_RECOGNITION = True

[Dashboard]
# Enable the diagnostics dashboard (using Tkinter).
ENABLE_DASHBOARD = True