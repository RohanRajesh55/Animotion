; =============================================================================
; ANIMOTION Configuration File
; =============================================================================
; This file defines configuration parameters for the ANIMOTION real-time 
; facial tracking and live animation project. Adjust these settings as needed 
; for calibration, thresholding, logging, and communication with the animation 
; backend and WebSocket server.
; =============================================================================

[Camera]
; Use 0 for the default webcam or provide the URL for an external camera feed.
DROIDCAM_URL = 0

[Thresholds]
; Thresholds for facial metrics.
EAR_THRESHOLD = 0.22

; Lower threshold for boosted accuracy
MAR_THRESHOLD = 0.25

; Optional toggle for normalization
MAR_NORMALIZE = True

EBR_THRESHOLD = 1.5
EMOTION_THRESHOLD = 0.4

[WebSocket]
; WebSocket connection details for transmitting facial tracking data.
VTS_WS_URL = ws://localhost:8001

; Replace with a secure authentication token.
AUTH_TOKEN = your_auth_token

[Logging]
; Logging configuration. Set to one of: DEBUG, INFO, WARNING, ERROR, CRITICAL.
LOG_LEVEL = INFO

[Animation]
; Smoothing factor for transitions (0 to 1, 1 = most smoothing).
SMOOTHING_FACTOR = 0.8

; Options: linear or cubic.
INTERPOLATION_TYPE = linear

[Calibration]
; (Optional) Camera calibration parameters. Leave blank to enable auto-calibration.
; Provide comma-separated values if manually calibrating.
; Example for CAMERA_MATRIX: 640, 0, 320, 0, 640, 240, 0, 0, 1
CAMERA_MATRIX =

; Example for CAMERA_DIST: 0.1, -0.25, 0, 0, 0
CAMERA_DIST =

[Advanced]
; Advanced settings for debugging and performance.
DEBUG_MODE = False
RUN_EMOTION_ANALYSIS = True
EMOTION_ANALYSIS_INTERVAL = 15

; New: Delay (in seconds) between each emotion prediction.
EMOTION_UPDATE_DELAY = 3.0
